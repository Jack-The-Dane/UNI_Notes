When many processes are executed in the same system, they access the  memory to:
-  Fetch instructions - in connection witth program execution
- Save data - as a result of calculations
- Retrieve data - which must be included in new calculations or something else.
Which means processes must share memory. We will learn here memory management techniques.

## Basic hardware
We must protect the operating system from access by user processes, as well as protect user processes from one another. This protection must be provided by the hardware. Each process has a separate memory space. Separate per-process memory space protects the processes from each other and is fundamental to having multiple processes loaded in  memory for concurrent execution.
To separate memory spaces, The base  register holds the smallest legal physical memory address while the limit register specifies the size of the range.

Protection of memory space is accomplished by having the CPU hardware compare every generated address with the registers.
Any attempt by a program executing in user mode to access operating-system memory or other users' memory results in a trap to the operating system, which treats the attempt as a fatal error.
This scheme prevents a user program from (accidentally or deliberately) modifying the code or
data structures of either the operating system or other users.
![[Pasted image 20231027093226.png]]

## Address binding
To run, the program must be brought into memory and placed within the context of a process. Most systems allow a user process to reside in any part of the physical memory. The binding of processes’ instructions and data to memory addresses can be done at any step along the way:
▪ Compile time: If you know at compile time where the process will reside in memory, then absolute code can be generated.
▪ Load time: If it is not known at compile time where the process will reside in memory, then the compiler must generate relocatable code.
i.e., final binding is delayed until load time.
▪ Execution time: If the process can be moved during its execution from one memory segment to another, then binding must be delayed until run time.
![[Pasted image 20231027093518.png]]

## Logical / Physical address space
**Logical address:** An address generated by the CPU.
**Physical address:** An address loaded into the memory-address register of the memory.
The set of all logical addresses generated by a program is a logical address space. The set of
all physical addresses corresponding to these logical addresses is a physical address space.
Binding addresses at either compile or load time generates identical logical and physical
addresses. However, the execution-time address-binding scheme results in different logical
and physical addresses.
The run-time mapping from logical to physical addresses is done by a hardware device called
the memory-management unit (MMU).

### Example 
MMU scheme is a generalization of the base-register scheme described before. The value in
the relocation register (base register) is added to every address generated by a user process
at the time the address is sent to memory.
The user program never accesses the real physical addresses, only generate logical
addresses, and thinks that the process runs in memory locations from 0 to max. However,
these logical addresses must be mapped to physical addresses ranging from R+0 to R+max.
The memory-mapping hardware separates the logical address space from the physical one.
![[Pasted image 20231027093848.png]]

## Optimization strategies
### Dynamic loading
Unlike before, where the entire program and all data of a process, should be in the physical memory when it was to be executed.
To obtain better memory-space utilization, we can use dynamic loading. A routine is not loaded until it is called. All routines are kept on disk in a relocatable load format. The basic idea here is that not all functionality in a program should be used every time. As a result, a program will take up less space, and there may be more processes in the memory at the same time – i.e., better utilization.
Dynamic loading does not require special support from the operating system. It is the responsibility of the users to design their programs to take advantage of such a method.

### Dynamic linking
Dynamically linked libraries (DLLs) (a.k.a. shared libraries) are system libraries that are linked to user programs when the programs are run. Some operating systems support only static linking, in which system libraries are treated like any other object module and are combined by the loader into the binary program image.
Dynamic linking, in contrast, is similar to dynamic loading. Here, though, linking, rather than loading, is postponed until execution time.
▪ Without this facility, each program on a system must include a copy of its (language) library in the executable image. This requirement not only increases the size of an executable image but also may waste main memory.
▪ A second advantage of DLLs is that these libraries can be shared among multiple processes, so that only one instance of the DLL in main memory.
Unlike dynamic loading, dynamic linking and shared libraries generally require help from the operating system. If the processes in memory are protected from one another, then the operating system is the only entity that can check to see whether the needed routine is in a memory space that can allow multiple processes to access.

## Contiguous memory allocation
### Memory protection
When the CPU scheduler selects a process for execution, the dispatcher loads the relocation and limit registers with the correct values as part of the context switch.
we can protect both the operating system and the other users' programs and data from being modified by this running process by checking against these registers.
![[Pasted image 20231027094514.png]]
Available memory blocks comprise a set of holes of various sizes scattered throughout memory. When a process arrives and needs memory, the system searches the set for a hole that is large enough for this process. The following 3 strategies can be used:
▪ First-fit: Allocates the first hole in the set of holes that is large enough for the process
▪ Best-fit: Allocates the smallest hole in the set of holes that is large enough for the  process
	o the entire set must be searched (unless it is sorted by size)
	o the strategy leaves the smallest hole in the memory (utilization)
▪ Worst-fit: Allocates the largest hole in the list
	o the entire set must be searched (unless it is sorted by size)
	o the strategy leaves the largest hole in the memory (which may be large enough and can be used for other processes.
First-fit and best-fit are better than worst-fit in terms of decreasing time and memory utilization.

### Fragmentation
Splitting up a larger memory block, so that only the necessary memory is allocated.

### Compaction
Moving memory blocks that are already allocated, as to avoid having small blocks of unused memory inbetween them, and instead having one large, unused block at the start or end of the address space.

## Segmentation
A memory management model that supports the user's view of memory
![[Pasted image 20231027095126.png]]
![[Pasted image 20231027095136.png]]
## Paging
### Hardware support
The implementation of paging involves breaking physical memory into fixed-sized blocks called frames and breaking logical memory into blocks of the same size called pages.
![[Pasted image 20231027095215.png]]

### Logical and physical memory
![[Pasted image 20231027095320.png]]

### Reducing access time using a TLB (Translation lookaside buffer)
![[Pasted image 20231027095423.png]]

### Free-frame list
The operating system keeps track of the available frames in a free-frame list
It is faster to assign the processes frames from this free-frame list than to first have to find them when they are to be used
![[Pasted image 20231027095559.png]]

### Protection
One additional bit is generally attached to each entry in the page table: a valid–invalid bit. When this bit is set to valid, the associated page is in the process's logical address space and is thus a legal (or valid) page. When the bit is set to invalid, the page is not in the process's logical address space.
![[Pasted image 20231027095651.png]]

### Shared pages
![[Pasted image 20231027095734.png]]

### Hierarchical page table structure
![[Pasted image 20231027095842.png]]
![[Pasted image 20231027095917.png]]

### Hashed page table
Often used for address spaces larger than 32-bit. If the address space becomes very large, clustered page table is used.
e.g.: $f_{hash}(p)$ → entry q (a linked list): p is compared to the first place in the list elements:
when p is found, r is used
(the list is there because multiple $f_{hash}(x)$ can lead to the same entry)
![[Pasted image 20231027100110.png]]

### Inverted Page Table
only one page table in the system, one entry for each page of phsical memory.
Reduces administration but loses the ability to share pages.
![[Pasted image 20231027100217.png]]

### Optimization strategies
#### Swapping
Swapping makes it possible for the total physical address space of all processes to exceed the real physical memory of the system, thus increasing the degree of multiprogramming in a system.
![[Pasted image 20231027100305.png]]

#### Swapping with paging
Here only a subset of the process pages is swapped in/out. Those that are not swapped here could be pages that contain I/O buffers.
![[Pasted image 20231027100356.png]]
